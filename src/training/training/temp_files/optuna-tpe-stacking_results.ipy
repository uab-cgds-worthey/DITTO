#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Oct  1 01:11:09 2020

@author: tarunmamidi
"""
import time
import os
import numpy as np; np.random.seed(5)  
import argparse
import yaml
import optuna
#from optuna.integration import TFKerasPruningCallback
#from optuna.integration.tensorboard import TensorBoardCallback
from optuna.samplers import TPESampler
import logging
#import tensorflow as tf
#import tensorflow.keras as keras
#try:
#    tf.get_logger().setLevel('INFO')
#except Exception as exc:
#    print(exc)
import warnings
warnings.simplefilter("ignore")
#import ray
#from tensorflow.keras.models import Sequential
#from tensorflow.keras.layers import Dense, Dropout, Activation
#from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
#from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, roc_auc_score, accuracy_score, confusion_matrix, recall_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression   #SGDClassifier, 
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.naive_bayes import GaussianNB
from imblearn.ensemble import BalancedRandomForestClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
import pandas as pd
import yaml
import matplotlib.pyplot as plt
from joblib import dump
import shap
import functools
print = functools.partial(print, flush=True)
#from joblib import dump, load


#EPOCHS = 150
class Objective(object):
    def __init__(self, train_x,test_x, train_y, test_y):
        
        self.train_x = train_x
        self.test_x = test_x
        self.train_y = train_y
        self.test_y = test_y
        #self.var = var
        #self.x = x
        #self.n_columns = 112
        #self.CLASS = 2

    def tuned_run(self, param): 
            model = StackingClassifier(estimators = [
                ('rf', RandomForestClassifier(random_state=42, n_estimators=param["rf_n_estimators"], criterion=param["rf_criterion"], max_depth=param["rf_max_depth"], min_samples_split=param["rf_min_samples_split"], min_samples_leaf=param["rf_min_samples_leaf"], max_features=param["rf_max_features"], oob_score=param["rf_oob_score"], class_weight=param["rf_class_weight"], n_jobs = -1)),
                ('knn', KNeighborsClassifier(n_neighbors=param["knn_n_neighbors"], weights=param["knn_weights"], algorithm=param["knn_algorithm"], p=param["knn_p"], metric=param["knn_metric"], n_jobs = -1)),    #leaf_size=leaf_size", 30), 
                ('gbc', GradientBoostingClassifier(random_state=42, loss=param["gbc_loss"], learning_rate = param["gbc_learning_rate"], n_estimators=param["gbc_n_estimators"], subsample=param["gbc_subsample"], criterion=param["gbc_criterion"], min_samples_split=param["gbc_min_samples_split"], min_samples_leaf=param["gbc_min_samples_leaf"], max_depth=param["gbc_max_depth"], max_features=param["gbc_max_features"])),
                ('dt', DecisionTreeClassifier(random_state=42, criterion=param["dt_criterion"], splitter=param["dt_splitter"], max_depth=param["dt_max_depth"], min_samples_split=param["dt_min_samples_split"], min_samples_leaf=param["dt_min_samples_leaf"], max_features=param["dt_max_features"], class_weight=param["dt_class_weight"])),
                ('gnb', GaussianNB(var_smoothing=param["var_smoothing"])),
                ('brf', BalancedRandomForestClassifier(random_state=42, n_estimators=param["brf_n_estimators"], criterion=param["brf_criterion"], max_depth=param["brf_max_depth"], min_samples_split=param["brf_min_samples_split"], min_samples_leaf=param["brf_min_samples_leaf"], max_features=param["brf_max_features"], oob_score=param["brf_oob_score"], class_weight=param["brf_class_weight"], n_jobs = -1)),
                ('lda', LinearDiscriminantAnalysis(solver=param["lda_solver"], shrinkage=param["lda_shrinkage"]))
                ],
                cv = 3,
                stack_method = "predict_proba",
                n_jobs=-1,
                passthrough=False,
                final_estimator= LogisticRegression(C=param["lr_C"], penalty=param["lr_penalty"], solver=param["lr_solver"], max_iter=param["lr_max_iter"], l1_ratio=param["lr_l1_ratio"], tol=param["lr_tol"], n_jobs = -1),
                verbose=0).fit(self.train_x, self.train_y)
            return model

    def show_result(self, study,var, output, feature_names):
            pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]
            complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
            print("Study statistics: ")
            print("  Number of finished trials: ", len(study.trials))
            print("  Number of pruned trials: ", len(pruned_trials))
            print("  Number of complete trials: ", len(complete_trials))
            print("Best trial:")
            trial = study.best_trial
            print("  Value: ", trial.value)
            print(f"Parameters: {trial.params}", file=open(output, "a"))
            model = self.tuned_run(trial.params)
            print('ran tuned model\n')
            with open(f"./tuning/{var}/StackingClassifier_{var}.joblib", 'wb') as f:
                dump(model, f, compress='lz4')
            train_score = model.score(self.train_x, self.train_y)
            y_score = model.predict(self.test_x)
            prc = precision_score(self.test_y,y_score, average="weighted")
            recall  = recall_score(self.test_y,y_score, average="weighted")
            roc_auc = roc_auc_score(self.test_y, y_score)
            accuracy = accuracy_score(self.test_y, y_score)
            matrix = confusion_matrix(self.test_y, y_score)
            #print(f'RandomForestClassifier: \nCross_validate(avg_train_score): {training_score}\nCross_validate(avg_test_score): {testing_score}\nPrecision: {prc}\nRecall: {recall}\nROC_AUC: {roc_auc}\nAccuracy: {accuracy}\nTime(in min): {finish}\nConfusion Matrix:\n{matrix}', file=open(output, "a"))
            clf_name = str(type(model)).split("'")[1]  #.split(".")[3]
            print('Model\ttrain_score\tPrecision\tRecall\troc_auc\tAccuracy\tConfusion_matrix[low_impact, high_impact]', file=open(output, "a"))    #\tConfusion_matrix[low_impact, high_impact]
            print(f'{clf_name}\t{train_score}\t{prc}\t{recall}\t{roc_auc}\t{accuracy}\n{matrix}', file=open(output, "a"))
            
            # explain all the predictions in the test set
            background = shap.kmeans(self.train_x, 10)
            explainer = shap.KernelExplainer(model.predict, background)
            background = self.test_x[np.random.choice(self.test_x.shape[0], 1000, replace=False)]
            shap_values = explainer.shap_values(background)
            plt.figure()
            shap.summary_plot(shap_values, background, feature_names, show=False)
            #shap.plots.beeswarm(shap_vals, feature_names)
            #shap.plots.waterfall(shap_values[1], max_display=10)
            plt.savefig(f"./tuning/{var}/StackingClassifier_{var}_features.pdf", format='pdf', dpi=1000, bbox_inches='tight')
            del background,shap_values, model, study
            return None



def data_parsing(var,config_dict,output):
    os.chdir('/data/project/worthey_lab/projects/experimental_pipelines/tarun/ditto/data/processed/')
    #Load data
    print(f'\nUsing merged_data-train_{var}..', file=open(output, "a"))
    X_train = pd.read_csv(f'train_{var}/merged_data-train_{var}.csv')
    #var = X_train[config_dict['ML_VAR']]
    X_train = X_train.drop(config_dict['ML_VAR'], axis=1)
    X_train.replace([np.inf, -np.inf], np.nan, inplace=True)
    X_train.fillna(0, inplace=True)
    feature_names = X_train.columns.tolist()
    X_train = X_train.values
    Y_train = pd.read_csv(f'train_{var}/merged_data-y-train_{var}.csv')
    Y_train = label_binarize(Y_train.values, classes=['low_impact', 'high_impact']).ravel() 

    X_test = pd.read_csv(f'test_{var}/merged_data-test_{var}.csv')
    #var = X_test[config_dict['ML_VAR']]
    X_test = X_test.drop(config_dict['ML_VAR'], axis=1)
    #feature_names = X_test.columns.tolist()
    X_test = X_test.values
    Y_test = pd.read_csv(f'test_{var}/merged_data-y-test_{var}.csv')
    print('Data Loaded!')
    #Y = pd.get_dummies(y)
    Y_test = label_binarize(Y_test.values, classes=['low_impact', 'high_impact']).ravel() 
    
    #scaler = StandardScaler().fit(X_train)
    #X_train = scaler.transform(X_train)
    #X_test = scaler.transform(X_test)
    # explain all the predictions in the test set
    return X_train, X_test, Y_train, Y_test,feature_names

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--vtype",
        type=str,
        default="non_snv",
        help="Type of variation/s (without spaces between) to hp the classifier (like: snv,non_snv,snv_protein_coding). (Default: non_snv)")
    parser.add_argument(
        "--cpus",
        type=int,
        default=10,
        help="Number of CPUs needed. (Default: 10)")
    parser.add_argument(
        "--gpus",
        type=int,
        default=0,
        help="Number of GPUs needed. (Default: 0)")
    parser.add_argument(
        "--mem",
        type=int,
        default=100*1024*1024*1024,
        help="Memory needed in bytes. (Default: 100*1024*1024*1024 (100GB))")

    args = parser.parse_args()

    variants = args.vtype.split(',')
      
    os.chdir('/data/project/worthey_lab/projects/experimental_pipelines/tarun/ditto/data/processed/')
    with open("../../configs/columns_config.yaml") as fh:
            config_dict = yaml.safe_load(fh)
        
    #variants = ['non_snv','snv','snv_protein_coding']
    for var in variants:
        start = time.perf_counter()
        if not os.path.exists('tuning/'+var):
            os.makedirs('./tuning/'+var)
        output = "tuning/"+var+"/ML_results_"+var+".csv"
        print('Working with '+var+' dataset...')
        X_train, X_test, Y_train, Y_test, feature_names = data_parsing(var,config_dict,output)
        
        print('Starting Objective...')
        objective = Objective(X_train, X_test, Y_train, Y_test)
        
        study = optuna.load_study(study_name= f"StackingClassifier_{var}", storage =f"sqlite:///tuning/{var}/StackingClassifier_{var}.db") 

        objective.show_result(study, var, output, feature_names)
        del X_train, X_test, Y_train, Y_test, feature_names
